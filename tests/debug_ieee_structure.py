#!/usr/bin/env python3
"""
Debug script –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã IEEE Spectrum
"""

import requests
from bs4 import BeautifulSoup
import re
import json

def analyze_ieee_page(url, topic):
    """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã IEEE Spectrum"""
    print(f"üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}")
    print("=" * 60)
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # –ò—â–µ–º —Å—Ç–∞—Ç—å–∏
        articles = soup.find_all('article')
        print(f"üì∞ –ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(articles)}")
        
        if articles:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—É—é —Å—Ç–∞—Ç—å—é
            first_article = articles[0]
            print(f"\nüîç –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç–∞—Ç—å–∏:")
            
            # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            title_selectors = ['h1', 'h2', 'h3', '.title', '.headline', '[data-testid="title"]']
            title = None
            for selector in title_selectors:
                title_elem = first_article.select_one(selector)
                if title_elem:
                    title = title_elem.get_text(strip=True)
                    print(f"   üìù –ó–∞–≥–æ–ª–æ–≤–æ–∫ ({selector}): {title[:100]}...")
                    break
            
            # –ò—â–µ–º —Å—Å—ã–ª–∫—É
            link_elem = first_article.find('a')
            if link_elem and link_elem.get('href'):
                link = link_elem.get('href')
                print(f"   üîó –°—Å—ã–ª–∫–∞: {link}")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∫—Ä–∏–ø—Ç—ã –≤ —Å—Ç–∞—Ç—å–µ
            scripts = first_article.find_all('script')
            print(f"\nüìú –ù–∞–π–¥–µ–Ω–æ —Å–∫—Ä–∏–ø—Ç–æ–≤: {len(scripts)}")
            
            for i, script in enumerate(scripts):
                script_content = script.string
                if script_content:
                    print(f"\nüîç –°–∫—Ä–∏–ø—Ç {i+1}:")
                    print(f"   –ö–ª–∞—Å—Å: {script.get('class', '')}")
                    print(f"   –î–ª–∏–Ω–∞: {len(script_content)} —Å–∏–º–≤–æ–ª–æ–≤")
                    
                    # –ò—â–µ–º JSON –¥–∞–Ω–Ω—ã–µ
                    if 'window.__INITIAL_STATE__' in script_content:
                        print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω INITIAL_STATE")
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON
                        json_match = re.search(r'window\.__INITIAL_STATE__\s*=\s*({.*?});', script_content, re.DOTALL)
                        if json_match:
                            try:
                                data = json.loads(json_match.group(1))
                                print(f"   üìä JSON –¥–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã")
                                # –ò—â–µ–º –¥–∞—Ç—É –≤ JSON
                                if 'article' in data:
                                    article_data = data['article']
                                    if 'publishedDate' in article_data:
                                        print(f"   üìÖ –î–∞—Ç–∞ –≤ JSON: {article_data['publishedDate']}")
                                    if 'date' in article_data:
                                        print(f"   üìÖ –î–∞—Ç–∞ –≤ JSON: {article_data['date']}")
                            except json.JSONDecodeError:
                                print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON")
                    
                    # –ò—â–µ–º –¥—Ä—É–≥–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å –¥–∞—Ç–∞–º–∏
                    date_patterns = [
                        r'"publishedDate"\s*:\s*"([^"]+)"',
                        r'"date"\s*:\s*"([^"]+)"',
                        r'"timestamp"\s*:\s*"([^"]+)"',
                        r'"createdAt"\s*:\s*"([^"]+)"',
                        r'"updatedAt"\s*:\s*"([^"]+)"'
                    ]
                    
                    for pattern in date_patterns:
                        matches = re.findall(pattern, script_content)
                        if matches:
                            print(f"   üìÖ –ù–∞–π–¥–µ–Ω—ã –¥–∞—Ç—ã ({pattern}): {matches[:3]}")
            
            # –ò—â–µ–º –¥–∞—Ç—É –≤ –æ–±—ã—á–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
            print(f"\nüìÖ –ü–æ–∏—Å–∫ –¥–∞—Ç—ã –≤ HTML —ç–ª–µ–º–µ–Ω—Ç–∞—Ö:")
            
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –¥–∞—Ç
            date_selectors = [
                'time', '.date', '.time', '[data-testid="date"]',
                '.article-date', '.post-date', '.published-date',
                '.meta-date', '.timestamp', '.publish-date',
                '.byline', '.author-info', '.meta',
                '[class*="date"]', '[class*="time"]', '[class*="published"]'
            ]
            
            for selector in date_selectors:
                date_elements = first_article.select(selector)
                if date_elements:
                    for elem in date_elements:
                        text = elem.get_text(strip=True)
                        datetime_attr = elem.get('datetime')
                        if text or datetime_attr:
                            print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–∞ –¥–∞—Ç–∞ ({selector}): text='{text}' datetime='{datetime_attr}'")
            
            # –ò—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç–∞—Ç—å–∏
            article_text = first_article.get_text()
            date_patterns = [
                r'\d{1,2}\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{4}',
                r'(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{1,2},?\s+\d{4}',
                r'\d{4}-\d{1,2}-\d{1,2}',
                r'\d{1,2}/\d{1,2}/\d{4}',
                r'(Today|Yesterday)',
                r'\d+\s+(hour|day|minute)s?\s+ago'
            ]
            
            found_dates = []
            for pattern in date_patterns:
                matches = re.findall(pattern, article_text, re.IGNORECASE)
                if matches:
                    found_dates.extend(matches)
            
            if found_dates:
                print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω—ã –¥–∞—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ: {found_dates[:3]}")
            else:
                print(f"   ‚ùå –î–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Ç–µ–∫—Å—Ç–µ")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            print(f"\nüîç –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –¥–∞—Ç–∞–º–∏:")
            for elem in first_article.find_all():
                for attr_name, attr_value in elem.attrs.items():
                    if isinstance(attr_value, str) and any(char.isdigit() for char in attr_value):
                        if any(date_word in attr_value.lower() for date_word in ['date', 'time', 'published', 'created']):
                            print(f"   {elem.name}.{attr_name}='{attr_value}'")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return False

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã IEEE Spectrum")
    print("=" * 60)
    
    urls = [
        ("AI", "https://spectrum.ieee.org/topic/artificial-intelligence"),
        ("Robotics", "https://spectrum.ieee.org/topic/robotics")
    ]
    
    for topic, url in urls:
        print(f"\n{'='*20} {topic} {'='*20}")
        analyze_ieee_page(url, topic)
        print()

if __name__ == "__main__":
    main() 