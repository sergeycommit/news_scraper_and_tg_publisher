#!/usr/bin/env python3
"""
–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ HTML —Å—Ç—Ä—É–∫—Ç—É—Ä—ã IEEE Spectrum
"""

import requests
from bs4 import BeautifulSoup
import sys
import os
import re

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ieee_spectrum_scraper import IEEESpectrumScraper

def debug_ieee_structure():
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ HTML —Å—Ç—Ä—É–∫—Ç—É—Ä—ã IEEE Spectrum"""
    
    scraper = IEEESpectrumScraper()
    
    # URL –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    test_url = "https://spectrum.ieee.org/thunderforge-ai-wargames-dod"
    
    print(f"üîç –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ HTML —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: {test_url}")
    print("=" * 70)
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        response = requests.get(test_url, headers=scraper.headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        print("üìÑ –ü–æ–∏—Å–∫ –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –¥–∞—Ç–∞–º–∏...")
        print("-" * 50)
        
        # –ò—â–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –¥–∞—Ç—ã
        all_elements_with_dates = []
        
        # –ò—â–µ–º –ø–æ –∫–ª–∞—Å—Å–∞–º, —Å–æ–¥–µ—Ä–∂–∞—â–∏–º "date"
        for elem in soup.find_all(class_=lambda x: x and 'date' in x.lower()):
            text = elem.get_text(strip=True)
            if text and any(char.isdigit() for char in text):
                all_elements_with_dates.append({
                    'element': elem,
                    'text': text,
                    'class': elem.get('class'),
                    'tag': elem.name,
                    'datetime': elem.get('datetime')
                })
        
        # –ò—â–µ–º time —ç–ª–µ–º–µ–Ω—Ç—ã
        for elem in soup.find_all('time'):
            text = elem.get_text(strip=True)
            if text:
                all_elements_with_dates.append({
                    'element': elem,
                    'text': text,
                    'class': elem.get('class'),
                    'tag': elem.name,
                    'datetime': elem.get('datetime')
                })
        
        # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º (3h, 1h, etc.)
        for elem in soup.find_all(text=True):
            if elem.parent and any(char.isdigit() for char in elem) and any(char.isalpha() for char in elem):
                text = elem.strip()
                if re.match(r'\d+[hdm]', text):  # 3h, 1h, 2d, etc.
                    all_elements_with_dates.append({
                        'element': elem.parent,
                        'text': text,
                        'class': elem.parent.get('class'),
                        'tag': elem.parent.name,
                        'datetime': elem.parent.get('datetime')
                    })
        
        print(f"üìÖ –ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –¥–∞—Ç–∞–º–∏: {len(all_elements_with_dates)}")
        
        for i, date_info in enumerate(all_elements_with_dates[:10]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
            print(f"\n{i+1}. –¢–µ–∫—Å—Ç: '{date_info['text']}'")
            print(f"   –¢–µ–≥: {date_info['tag']}")
            print(f"   –ö–ª–∞—Å—Å: {date_info['class']}")
            if date_info['datetime']:
                print(f"   datetime: '{date_info['datetime']}'")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π —ç–ª–µ–º–µ–Ω—Ç
            parent = date_info['element'].parent
            if parent:
                print(f"   –†–æ–¥–∏—Ç–µ–ª—å: {parent.name} (–∫–ª–∞—Å—Å: {parent.get('class')})")
        
        print(f"\nüîç –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ AI...")
        print("-" * 50)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É AI
        ai_response = requests.get("https://spectrum.ieee.org/topic/artificial-intelligence", headers=scraper.headers, timeout=30)
        ai_response.raise_for_status()
        ai_soup = BeautifulSoup(ai_response.content, 'html.parser')
        
        # –ò—â–µ–º –≤—Å–µ article —ç–ª–µ–º–µ–Ω—Ç—ã
        articles = ai_soup.find_all('article')
        print(f"üì∞ –ù–∞–π–¥–µ–Ω–æ article —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(articles)}")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 3 —Å—Ç–∞—Ç—å–∏
        for i, article in enumerate(articles[:3]):
            print(f"\nüìÑ –°—Ç–∞—Ç—å—è {i+1}:")
            
            # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            title_elem = article.find(['h1', 'h2', 'h3', 'h4'])
            if title_elem:
                title = title_elem.get_text(strip=True)
                print(f"   –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title[:60]}...")
            
            # –ò—â–µ–º —Å—Å—ã–ª–∫—É
            link_elem = article.find('a')
            if link_elem:
                href = link_elem.get('href')
                if href:
                    if not href.startswith('http'):
                        href = f"https://spectrum.ieee.org{href}"
                    print(f"   –°—Å—ã–ª–∫–∞: {href}")
            
            # –ò—â–µ–º –¥–∞—Ç—É –≤ —Å—Ç–∞—Ç—å–µ
            date_found = False
            for date_info in all_elements_with_dates:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ —ç–ª–µ–º–µ–Ω—Ç –¥–∞—Ç—ã –≤–Ω—É—Ç—Ä–∏ —ç—Ç–æ–π —Å—Ç–∞—Ç—å–∏
                if date_info['element'] in article.descendants:
                    print(f"   –î–∞—Ç–∞: '{date_info['text']}' (–Ω–∞–π–¥–µ–Ω–∞ –≤ —Å—Ç–∞—Ç—å–µ)")
                    date_found = True
                    break
            
            if not date_found:
                print(f"   –î–∞—Ç–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
            # –ò—â–µ–º –¥–∞—Ç—É –≤ —Å–∞–º–æ–π —Å—Ç–∞—Ç—å–µ
            article_dates = []
            for elem in article.find_all(class_=lambda x: x and 'date' in x.lower()):
                text = elem.get_text(strip=True)
                if text and any(char.isdigit() for char in text):
                    article_dates.append(text)
            
            for elem in article.find_all('time'):
                text = elem.get_text(strip=True)
                if text:
                    article_dates.append(text)
            
            if article_dates:
                print(f"   –î–∞—Ç—ã –≤ —Å—Ç–∞—Ç—å–µ: {article_dates}")
            else:
                print(f"   –î–∞—Ç—ã –≤ —Å—Ç–∞—Ç—å–µ: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç–∞—Ç—å–µ
        print(f"\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å—Ç–∞—Ç—å–µ Thunderforge...")
        print("-" * 60)
        
        # –ò—â–µ–º —Å—Ç–∞—Ç—å—é —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º "Thunderforge"
        thunderforge_article = None
        for article in articles:
            title_elem = article.find(['h1', 'h2', 'h3', 'h4'])
            if title_elem and 'Thunderforge' in title_elem.get_text():
                thunderforge_article = article
                break
        
        if thunderforge_article:
            print("‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Å—Ç–∞—Ç—å—è Thunderforge")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            article_info = scraper.extract_article_info(thunderforge_article, "AI")
            if article_info:
                print(f"‚úÖ –ó–∞–≥–æ–ª–æ–≤–æ–∫: {article_info['title']}")
                print(f"‚úÖ –°—Å—ã–ª–∫–∞: {article_info['link']}")
                print(f"‚úÖ –ê–≤—Ç–æ—Ä: {article_info['author']}")
                print(f"‚úÖ –î–∞—Ç–∞ (—Ç–µ–∫—Å—Ç): '{article_info['date']}'")
                print(f"‚úÖ –î–∞—Ç–∞ (–ø–∞—Ä—Å–∏–Ω–≥): {article_info['parsed_date']}")
                print(f"‚úÖ –°—Ç–∞—Ç—å—è –∑–∞ —Å–µ–≥–æ–¥–Ω—è: {article_info['parsed_date'] == scraper.today if article_info['parsed_date'] else False}")
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞—Ç—å–µ")
        else:
            print("‚ùå –°—Ç–∞—Ç—å—è Thunderforge –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Å–ø–∏—Å–∫–µ —Å—Ç–∞—Ç–µ–π")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    debug_ieee_structure() 